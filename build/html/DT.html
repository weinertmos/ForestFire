<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Growing a single Decision Tree &#8212; ForestFire 1.0.0 documentation</title>
    
    <link rel="stylesheet" href="_static/haiku.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     '1.0.0',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true,
        SOURCELINK_SUFFIX: '.txt'
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Growing a Random Forest" href="RF.html" />
    <link rel="prev" title="Execution" href="execution.html" /> 
  </head>
  <body role="document">
      <div class="header" role="banner"><h1 class="heading"><a href="index.html">
          <span>ForestFire 1.0.0 documentation</span></a></h1>
        <h2 class="heading"><span>Growing a single Decision Tree</span></h2>
      </div>
      <div class="topnav" role="navigation" aria-label="top navigation">
      
        <p>
        «&#160;&#160;<a href="execution.html">Execution</a>
        &#160;&#160;::&#160;&#160;
        <a class="uplink" href="index.html">Contents</a>
        &#160;&#160;::&#160;&#160;
        <a href="RF.html">Growing a Random Forest</a>&#160;&#160;»
        </p>

      </div>
      <div class="content">
        
        
  <div class="section" id="growing-a-single-decision-tree">
<span id="singletree"></span><h1>Growing a single Decision Tree<a class="headerlink" href="#growing-a-single-decision-tree" title="Permalink to this headline">¶</a></h1>
<p>The basic principle of building decision trees is based on the implementation of decision trees in <a class="reference internal" href="Overview.html#collective-intelligence" id="id1">[Collective_Intelligence]</a> by Toby Segaran.</p>
<div class="section" id="base-class">
<h2>Base Class<a class="headerlink" href="#base-class" title="Permalink to this headline">¶</a></h2>
<p>At the foundation of the ForestFire algorithm stands the <a class="reference internal" href="#decisionnode"><span class="std std-ref">decisionnode class</span></a>.
It represents a point in a <a class="reference internal" href="Overview.html#dt"><span class="std std-ref">DT</span></a> at which the decision is made into which branch (true or false) to proceed.
The whole tree is built up of nodes.
Each node itself can contain two more nodes - the true and false branch - which are themselves decisionnodes.
In this way a tree is constructed in which a set of data takes a certain path along the tree to get classified.
At each node it either enters the true or the false branch.
When a branch is reached with no further branches below, this is called a leaf node.
The leaf node contains the results which represent the classification a data set receives.
The results can be a single value - in this case the classification is 100% this single value.
It can also consist of several values, e.g. value1 with 2 instances and value2 with 1 instance.
The result of this classification is ambiguous, so it is expressed as a probability: the classification is 1/3 value2 and 2/3 value1.</p>
</div>
<div class="section" id="helper-functions">
<h2>Helper Functions<a class="headerlink" href="#helper-functions" title="Permalink to this headline">¶</a></h2>
<p>At each node two questions have to be answered:</p>
<ul class="simple">
<li><dl class="first docutils">
<dt>By which feature (=column) should the next decision be made?</dt>
<dd>The feature that is chosen at the first node should be the one feature that separates the data set in the best possible way. Latter features are of less importance</dd>
</dl>
</li>
<li>By which value should the decision be made?</li>
</ul>
<p>To answer those questions the data is iteratively split in every possible way.
This means it is split for every feature and within every feature it is split for every single value.</p>
<p>See <a class="reference internal" href="#divideset"><span class="std std-ref">divideset</span></a></p>
<p>Each of the resulting splits has to be evaluted with respect to &#8220;how well&#8221; the split separates the big list into two smaller lists.
For this three evaluation metrics can be chosen from:</p>
<blockquote>
<div><ul class="simple">
<li><dl class="first docutils">
<dt><a class="reference internal" href="#giniimpurity"><span class="std std-ref">Gini Impurity</span></a></dt>
<dd>&#8220;Probability that a randomly placed item will be in the wrong category&#8221;</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><a class="reference internal" href="#entropy"><span class="std std-ref">Entropy</span></a></dt>
<dd>&#8220;How mixed is a list&#8221;</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><a class="reference internal" href="#variance"><span class="std std-ref">Variance</span></a></dt>
<dd>&#8220;How far apart do the numbers lie&#8221;</dd>
</dl>
</li>
</ul>
</div></blockquote>
<p>The evaluation metric returns the gini coefficient / entropy / variance of the list that it is presented with.
Both methods need information about how many unique elements are in one list.
See <a class="reference internal" href="#uniquecounts"><span class="std std-ref">uniquecounts</span></a>.</p>
<p>After a tree is built its width and depth can be examined by <a class="reference internal" href="#getdepth"><span class="std std-ref">getdepth</span></a> and <a class="reference internal" href="#getwidth"><span class="std std-ref">getwidth</span></a>.
A tree&#8217;s depth is the maximum number of decisions that can be made before reaching a leaf node plus 1 (A tree stump that has no branches by definition still has a depth of 1).
A tree&#8217;s width is the number of leaves it contains, i.e. number of nodes that have entries in their results property.</p>
</div>
<div class="section" id="building-a-tree">
<h2>Building a tree<a class="headerlink" href="#building-a-tree" title="Permalink to this headline">¶</a></h2>
<p>Starting with a root node and the whole provided data set the <a class="reference internal" href="#buildtree"><span class="std std-ref">buildtree</span></a> function recursively
loops through the following steps and builds up the tree structure:</p>
<blockquote>
<div><ol class="arabic simple">
<li>create a decisionnode</li>
<li>calculate score (entropy / gini coefficient / variance) of current list</li>
<li>divide list into every possible split</li>
<li>evaluate each split according to evaluation metric</li>
<li>split the list into true and false branches according to best evaluated split</li>
<li>If no split is better than the current list no split is performed and results are stored, tree is returned</li>
<li>If true and false branches are created, start at 1.</li>
</ol>
</div></blockquote>
<p>An example tree can look like <a class="reference internal" href="#treeview"><span class="std std-ref">this</span></a>.
The first node checks if the value of the third column is &gt;= 21.
If yes it continues to the right and checks column 0 if the value is equal to &#8216;slashdot&#8217;.
If yes the prediction for the new data set will be 50% None and 50% Premium since both values have appeared 1 time during trainging/building of the tree.</p>
<p>If the value of column 0 is instead not equal to &#8216;slashdot&#8217;, there is another query at the next node for colum 0 wether it is equal to &#8216;google&#8217; and so on.</p>
<div class="figure align-center" id="id2">
<span id="treeview"></span><a class="reference internal image-reference" href="_images/treeview.jpg"><img alt="treeview.jpg" src="_images/treeview.jpg" style="width: 640.0px; height: 496.0px;" /></a>
<p class="caption"><span class="caption-text">Treeview.jpg</span></p>
</div>
<div class="section" id="pruning-a-tree">
<h3>Pruning a tree<a class="headerlink" href="#pruning-a-tree" title="Permalink to this headline">¶</a></h3>
<p>At the deeper levels of a tree there might be splits that further reduce the entropy / gini coefficient / variance of the data, but only to a minor degree.
These further splits are not productive since they make the tree more complex but yield only small improvements.
There are two ways of tackling this problem.</p>
<p>One is to stop splitting the data if the split does not produce a significant reduction in entropy / gini coefficient / variance.
The danger in doing this is that there is a possibility that at an even later split there might be a significant reduction, but the algorithm can not forsee this.
This would lead to an premature stop.</p>
<p>The better way of dealing with the subject of overly complex trees is <a class="reference internal" href="#prune"><span class="std std-ref">pruning</span></a>.
The pruning approach builds up the whole complex tree and then starts from its leaves going up.
It takes a look at the information gain that is made by the preceding split.
If the gain is lower than a threshold specified by the <em>pruning</em> hyperparameter in <a class="reference internal" href="execution.html#execution"><span class="std std-ref">Execution</span></a> it will reunite the two leaves into one single leaf.
This way no meaningful splits are abandoned but complexity can be reduced</p>
<p>In the <a class="reference internal" href="#treeview"><span class="std std-ref">above example tree</span></a> the rightmost leaf is the only place where pruning might have hapenned.
Before pruning &#8216;None&#8217; and &#8216;Premium&#8217; could have been located in separate leaves.
If the information gain from splitting the two was below the defined threshold, those two leaves would get pruned into one single leaf.
Still, only by looking at the finished tree one cannot tell if the tree was pruned or if it has been built this way (meaning that already during building there was no benefit in creating another split).</p>
<div class="admonition warning">
<p class="first admonition-title">Warning</p>
<p>By default pruning is disabled (set to 0).
A reasonable value for pruning depends on the raw data.
Observe the output for &#8220;wrongs&#8221; on the console.
By default it should be quite small (&lt;10% of the total number of trees at most).
Try a value for pruning between 0 and 1 and only increase above 1 if the &#8220;wrongs&#8221; output does not get too big.</p>
<p>A &#8220;wrong&#8221; tree is a tree &#8220;stump&#8221; consisting of only one node.
Such a tree has no informational benefit.</p>
<p class="last">Being an advanced hyperparameter pruning can greatly improve overall results as well as the number of runs it takes to find a good result.
But it also increases the risk of getting stuck in a local extremum or ending up with a lot of tree &#8216;stumps&#8217; that are useless for further information retrieval.</p>
</div>
</div>
</div>
<div class="section" id="classifying-new-observations">
<h2>Classifying new observations<a class="headerlink" href="#classifying-new-observations" title="Permalink to this headline">¶</a></h2>
<p>After a <a class="reference internal" href="Overview.html#dt"><span class="std std-ref">DT</span></a> is built new observations can be classified.
This process can vividly be explained by starting at the top node and asking a simple yes or no question about the corresponding feature and value that is stored in the node.
If the answer for the new observastion is yes, the path follows the true branch of the node.
In case of a negated answer the false branch is pursued.</p>
<p>See <a class="reference internal" href="#treeview"><span class="std std-ref">Tree Image</span></a> as an example. Visually the true branch is on the right hand side of the parent node, the false branch on the left.</p>
<p>The classification of new data is done with the help of the <a class="reference internal" href="#classify"><span class="std std-ref">classify function</span></a>.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last"><a class="reference internal" href="#classify"><span class="std std-ref">classify</span></a> is also able to handle missing data entries.
In this case both branches are followed and the result is weighted according to the number of entries they contain.
Since the ForestFire algorithm produces its own database from the raw data and the underlying <a class="reference internal" href="Overview.html#mla"><span class="std std-ref">MLA</span></a> it is made sure that there are always entries present and the case of missing entries does not come to pass.</p>
</div>
</div>
<div class="section" id="visualizing-a-tree">
<h2>Visualizing a tree<a class="headerlink" href="#visualizing-a-tree" title="Permalink to this headline">¶</a></h2>
<p>The following functions are for debugging purposes only.</p>
<p>The structure of the tree can be output to the console with the help of <a class="reference internal" href="#printtree"><span class="std std-ref">printtree</span></a>.</p>
<p>An image of the tree can be created with the <a class="reference internal" href="#drawtree"><span class="std std-ref">drawtree</span></a> function.
It makes use of <a class="reference internal" href="#drawnode"><span class="std std-ref">drawnode</span></a>.</p>
</div>
<div class="section" id="storing-the-tree-structure">
<h2>Storing the tree structure<a class="headerlink" href="#storing-the-tree-structure" title="Permalink to this headline">¶</a></h2>
<p>To <a class="reference internal" href="RF.html#random-forest"><span class="std std-ref">grow a Random Forest from single Decision Trees</span></a> there must be a way to store whole trees and their structure in an array.
Unlike <a class="reference internal" href="#printtree"><span class="std std-ref">printtree</span></a> and <a class="reference internal" href="#drawtree"><span class="std std-ref">drawtree</span></a> where the tree is printed / drawn recursively by looping through the nodes.</p>
<p>This is done with the help of <a class="reference internal" href="#pathgen"><span class="std std-ref">path_gen</span></a> and <a class="reference internal" href="#pathgen2"><span class="std std-ref">path_gen2</span></a>.
By examining the last column of the path matrix that is returned by <a class="reference internal" href="#pathgen"><span class="std std-ref">path_gen</span></a> all results of the different leaf nodes can be reached.</p>
<p>Another usefull function is <a class="reference internal" href="#checkpath"><span class="std std-ref">check_path</span></a>. It takes as input a tree and a result (typically extracted from a path matrix) and checks wether the result is in that tree. This way it is possible to move along the branches of a tree and at each node check if it (still) contains a certain result, e.g. the best result of the whole tree. This is used for determining the importance of features in the following chapter about <a class="reference internal" href="RF.html#random-forest"><span class="std std-ref">growing a Random Forest</span></a></p>
<div class="admonition important">
<p class="first admonition-title">Important</p>
<p><strong>Functions used in this chapter</strong></p>
<span class="target" id="decisionnode"></span><dl class="class">
<dt id="ForestFire.Main.decisionnode">
<em class="property">class </em><code class="descclassname">ForestFire.Main.</code><code class="descname">decisionnode</code><span class="sig-paren">(</span><em>col=-1</em>, <em>value=None</em>, <em>results=None</em>, <em>tb=None</em>, <em>fb=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ForestFire/Main.html#decisionnode"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ForestFire.Main.decisionnode" title="Permalink to this definition">¶</a></dt>
<dd><p>Base class that a decision tree is built of.</p>
<dl class="docutils">
<dt>Keyword Arguments:</dt>
<dd><ul class="first last simple">
<li>col {integer} &#8211; column number = decision criterium for splitting data (default: {-1})</li>
<li>value {integer/float/string} &#8211; value by which data gets split (default: {None})</li>
<li>results {integer/float/string} &#8211; if node is an end node (=leaf) it contains the results (default: {None})</li>
<li>tb {decisionnode} &#8211; next smaller node containing the true branch (default: {None})</li>
<li>fb {decisionnode} &#8211; next smaller node containing the false branch (default: {None})</li>
</ul>
</dd>
</dl>
</dd></dl>

<span class="target" id="divideset"></span><dl class="function">
<dt id="ForestFire.Main.divideset">
<code class="descclassname">ForestFire.Main.</code><code class="descname">divideset</code><span class="sig-paren">(</span><em>rows</em>, <em>column</em>, <em>value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ForestFire/Main.html#divideset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ForestFire.Main.divideset" title="Permalink to this definition">¶</a></dt>
<dd><p>splits a data set into two separate sets according to the column and the value that is passed into.</p>
<p>If value is a number the comparison is done with &lt;= and &gt;=.
If value is not a number the exact value is compared</p>
<dl class="docutils">
<dt>Arguments:</dt>
<dd><ul class="first last simple">
<li>rows {list} &#8211; data set that is split</li>
<li>column{integer} &#8211; column by which data gets split</li>
<li>value {number/string} &#8211; value by which data gets split</li>
</ul>
</dd>
<dt>Returns:</dt>
<dd>[list] &#8211; two lists</dd>
</dl>
</dd></dl>

<span class="target" id="giniimpurity"></span><dl class="function">
<dt id="ForestFire.Main.giniimpurity">
<code class="descclassname">ForestFire.Main.</code><code class="descname">giniimpurity</code><span class="sig-paren">(</span><em>rows</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ForestFire/Main.html#giniimpurity"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ForestFire.Main.giniimpurity" title="Permalink to this definition">¶</a></dt>
<dd><p>Probability that a randomly placed item will be in the wrong category</p>
<p>Calculates the probability of each possible outcome by dividing the number of times that outcome occurs
by the total number of rows in the set. 
It then adds up the products of all these probabilities. 
This gives the overall chance that a row would be randomly assigned to the wrong outcome. 
The higher this probability, the worse the split.</p>
<dl class="docutils">
<dt>Returns:</dt>
<dd>float &#8211; probability of being in the wrong category</dd>
</dl>
</dd></dl>

<span class="target" id="entropy"></span><dl class="function">
<dt id="ForestFire.Main.entropy">
<code class="descclassname">ForestFire.Main.</code><code class="descname">entropy</code><span class="sig-paren">(</span><em>rows</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ForestFire/Main.html#entropy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ForestFire.Main.entropy" title="Permalink to this definition">¶</a></dt>
<dd><p>Entropy is the sum of p(x)log(p(x)) across all the different possible results &#8211;&gt; how mixed is a list</p>
<p>Funciton calculates the frequency of each item (the number of times it appears divided by the total number of rows)
and applies these formulas:</p>
<div class="math">
<p><img src="_images/math/7b6055722ebd5c3031c5efae30128b4b769f485c.png" alt="p(i) = frequency(outcome) = \dfrac{count(outcome)}{count(total rows)}

Entropy = \sum(p(i)) \cdot  \log(p(i)) \ for \ all \ outcomes"/></p>
</div><p>The higher the entropy, the worse the split.</p>
<dl class="docutils">
<dt>Arguments:</dt>
<dd>rows {list} &#8211; list to evaluate</dd>
<dt>Returns:</dt>
<dd>[float] &#8211; entropy of the list</dd>
</dl>
</dd></dl>

<span class="target" id="variance"></span><dl class="function">
<dt id="ForestFire.Main.variance">
<code class="descclassname">ForestFire.Main.</code><code class="descname">variance</code><span class="sig-paren">(</span><em>rows</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ForestFire/Main.html#variance"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ForestFire.Main.variance" title="Permalink to this definition">¶</a></dt>
<dd><p>Evaluates how close together numerical values lie</p>
<p>Calculates mean and variance for given list</p>
<div class="math">
<p><img src="_images/math/1d35f35110dc1b81d5f8577eae14f0a384ab2954.png" alt="mean = \dfrac{\sum(entries)}{number \ of \ entries}

variance = \sum(entry - mean) ^ 2"/></p>
</div><dl class="docutils">
<dt>Arguments:</dt>
<dd>rows {list} &#8211; list to evaluate</dd>
<dt>Returns:</dt>
<dd>number &#8211; variance of the list</dd>
</dl>
</dd></dl>

<span class="target" id="uniquecounts"></span><dl class="function">
<dt id="ForestFire.Main.uniquecounts">
<code class="descclassname">ForestFire.Main.</code><code class="descname">uniquecounts</code><span class="sig-paren">(</span><em>rows</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ForestFire/Main.html#uniquecounts"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ForestFire.Main.uniquecounts" title="Permalink to this definition">¶</a></dt>
<dd><p>evaluate how many unique elements are in a given list</p>
<dl class="docutils">
<dt>Arguments:</dt>
<dd>rows {list} &#8211; evaluated list</dd>
<dt>Returns:</dt>
<dd>integer &#8211; number of unique elements</dd>
</dl>
</dd></dl>

<span class="target" id="getdepth"></span><dl class="function">
<dt id="ForestFire.Main.getdepth">
<code class="descclassname">ForestFire.Main.</code><code class="descname">getdepth</code><span class="sig-paren">(</span><em>tree</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ForestFire/Main.html#getdepth"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ForestFire.Main.getdepth" title="Permalink to this definition">¶</a></dt>
<dd><p>returns the maximum number of consecutive nodes</p>
<dl class="docutils">
<dt>Arguments:</dt>
<dd>tree {decisionnode} &#8211; tree to examine</dd>
<dt>Returns:</dt>
<dd>number &#8211; maximum number of consecutive nodes</dd>
</dl>
</dd></dl>

<span class="target" id="getwidth"></span><dl class="function">
<dt id="ForestFire.Main.getwidth">
<code class="descclassname">ForestFire.Main.</code><code class="descname">getwidth</code><span class="sig-paren">(</span><em>tree</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ForestFire/Main.html#getwidth"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ForestFire.Main.getwidth" title="Permalink to this definition">¶</a></dt>
<dd><p>returns the number of leaves = endnodes in the tree</p>
<dl class="docutils">
<dt>Arguments:</dt>
<dd>tree {decisionnode} &#8211; tree to examine</dd>
<dt>Returns:</dt>
<dd>number &#8211; number of endnodes</dd>
</dl>
</dd></dl>

<span class="target" id="buildtree"></span><dl class="function">
<dt id="ForestFire.Main.buildtree">
<code class="descclassname">ForestFire.Main.</code><code class="descname">buildtree</code><span class="sig-paren">(</span><em>rows</em>, <em>scoref</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ForestFire/Main.html#buildtree"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ForestFire.Main.buildtree" title="Permalink to this definition">¶</a></dt>
<dd><p>recursively builds decisionnode objects that form a decision tree</p>
<p>At each node the best possible split is calculated (depending on the evaluation metric).
If no further split is neccessary the remaining items and their number of occurence 
are written in the results property.</p>
<dl class="docutils">
<dt>Arguments:</dt>
<dd>rows {list} &#8211; dataset from which to build the tree
scoref {function} &#8211; evaluation metric (entropy / gini coefficient)</dd>
<dt>Returns:</dt>
<dd>decisionnode &#8211; either two decisionnodes for true and false branch or one decisionnode with results (leaf node)</dd>
</dl>
</dd></dl>

<span class="target" id="prune"></span><dl class="function">
<dt id="ForestFire.Main.prune">
<code class="descclassname">ForestFire.Main.</code><code class="descname">prune</code><span class="sig-paren">(</span><em>tree</em>, <em>mingain</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ForestFire/Main.html#prune"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ForestFire.Main.prune" title="Permalink to this definition">¶</a></dt>
<dd><p>prunes the leaves of a tree in order to reduce complexity</p>
<p>By looking at the information gain that is achieved by splitting data further and further and checking if
it is above the mingain threshold, neighbouring leaves can be collapsed to a single leaf.</p>
<dl class="docutils">
<dt>Arguments:</dt>
<dd>tree {decisionnode} &#8211; tree that gets pruned
mingain {number} &#8211; threshold for pruning</dd>
</dl>
</dd></dl>

<span class="target" id="printtree"></span><dl class="function">
<dt id="ForestFire.Main.printtree">
<code class="descclassname">ForestFire.Main.</code><code class="descname">printtree</code><span class="sig-paren">(</span><em>tree</em>, <em>indent=' '</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ForestFire/Main.html#printtree"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ForestFire.Main.printtree" title="Permalink to this definition">¶</a></dt>
<dd><p>prints out the tree on the command line</p>
<dl class="docutils">
<dt>Arguments:</dt>
<dd>tree {decisionnode} &#8211; tree that gets printed</dd>
</dl>
</dd></dl>

<span class="target" id="drawtree"></span><dl class="function">
<dt id="ForestFire.Main.drawtree">
<code class="descclassname">ForestFire.Main.</code><code class="descname">drawtree</code><span class="sig-paren">(</span><em>tree</em>, <em>jpeg='tree.jpg'</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ForestFire/Main.html#drawtree"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ForestFire.Main.drawtree" title="Permalink to this definition">¶</a></dt>
<dd><p>visualization of the tree in a jpeg</p>
<dl class="docutils">
<dt>Arguments:</dt>
<dd>tree {decisionnode} &#8211; tree to draw</dd>
<dt>Keyword Arguments:</dt>
<dd>jpeg {str} &#8211; Name of the .jpg (default: {&#8216;tree.jpg&#8217;})</dd>
</dl>
</dd></dl>

<span class="target" id="drawnode"></span><dl class="function">
<dt id="ForestFire.Main.drawnode">
<code class="descclassname">ForestFire.Main.</code><code class="descname">drawnode</code><span class="sig-paren">(</span><em>draw</em>, <em>tree</em>, <em>x</em>, <em>y</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ForestFire/Main.html#drawnode"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ForestFire.Main.drawnode" title="Permalink to this definition">¶</a></dt>
<dd><p>Helper Function for drawtree, draws a single node</p>
<dl class="docutils">
<dt>Arguments:</dt>
<dd>draw {img} &#8211; node to be drawn
tree {decisionnode} &#8211; tree that the node belongs to
x {number} &#8211; x location
y {number} &#8211; y location</dd>
</dl>
</dd></dl>

<span class="target" id="classify"></span><dl class="function">
<dt id="ForestFire.Main.classify">
<code class="descclassname">ForestFire.Main.</code><code class="descname">classify</code><span class="sig-paren">(</span><em>observation</em>, <em>tree</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ForestFire/Main.html#classify"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ForestFire.Main.classify" title="Permalink to this definition">¶</a></dt>
<dd><p>takes a new data set that gets classified and the tree that determines the classification and returns the estimated result.</p>
<dl class="docutils">
<dt>Arguments:</dt>
<dd>observation {numpy.array} &#8211; the new data set that gets classified, e.g. test data set
tree {decisionnode} &#8211; tree that observation gets classified in</dd>
<dt>Returns:</dt>
<dd>data &#8211; expected result</dd>
</dl>
</dd></dl>

<span class="target" id="pathgen"></span><dl class="function">
<dt id="ForestFire.Main.path_gen">
<code class="descclassname">ForestFire.Main.</code><code class="descname">path_gen</code><span class="sig-paren">(</span><em>tree</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ForestFire/Main.html#path_gen"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ForestFire.Main.path_gen" title="Permalink to this definition">¶</a></dt>
<dd><p>Create a path Matrix which contains the structure of the tree. Calls path_gen2 to do so.</p>
<dl class="docutils">
<dt>Arguments:</dt>
<dd>tree {decisionnode} &#8211; tree of which the data structure is stored</dd>
<dt>Returns:</dt>
<dd>numpy.array &#8211; data structure of the tree, NaN means there is no more branch</dd>
</dl>
</dd></dl>

<span class="target" id="pathgen2"></span><dl class="function">
<dt id="ForestFire.Main.path_gen2">
<code class="descclassname">ForestFire.Main.</code><code class="descname">path_gen2</code><span class="sig-paren">(</span><em>tree</em>, <em>width</em>, <em>depth</em>, <em>path</em>, <em>z2</em>, <em>z1</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ForestFire/Main.html#path_gen2"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ForestFire.Main.path_gen2" title="Permalink to this definition">¶</a></dt>
<dd><p>Create a path Matrix which contains the structure of the tree.</p>
<p>creates a matrix &#8216;path&#8217; that represents the structure of the tree and the decisions made at each node, last column contains the average MSE at that leaf
the sooner a feature gets chosen as a split feature the more important it is (the farther on the left it appears in path matrix)
order that leaves are written in (top to bottom): function will crawl to the rightmost leaf first (positive side), then jump back up one level and move one step to the left (loop)</p>
<dl class="docutils">
<dt>Arguments:</dt>
<dd>tree {decisionnode} &#8211; tree of which the data structure is stored 
width {int} &#8211; width of the tree
depth {int} &#8211; depth of the tree
path {[type]} &#8211; current path matrix, gets updated during function calls
z2 {int} &#8211; control variable for current depth
z1 {int} &#8211; control variable for current width</dd>
<dt>Returns:</dt>
<dd>numpy.array &#8211; the structure of the tree</dd>
</dl>
</dd></dl>

<span class="target" id="checkpath"></span><dl class="last function">
<dt id="ForestFire.Main.check_path">
<code class="descclassname">ForestFire.Main.</code><code class="descname">check_path</code><span class="sig-paren">(</span><em>tree</em>, <em>result</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ForestFire/Main.html#check_path"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ForestFire.Main.check_path" title="Permalink to this definition">¶</a></dt>
<dd><p>Check if a tree contains MSE_min (= True) or not (= False)</p>
<dl class="docutils">
<dt>Arguments:</dt>
<dd>tree {decisionnode} &#8211; tree that gets searched for result
result {data} &#8211; result that the tree is searched for</dd>
<dt>Returns:</dt>
<dd>bool &#8211; True if result is in the tree, false if not</dd>
</dl>
</dd></dl>

</div>
</div>
</div>


      </div>
      <div class="bottomnav" role="navigation" aria-label="bottom navigation">
      
        <p>
        «&#160;&#160;<a href="execution.html">Execution</a>
        &#160;&#160;::&#160;&#160;
        <a class="uplink" href="index.html">Contents</a>
        &#160;&#160;::&#160;&#160;
        <a href="RF.html">Growing a Random Forest</a>&#160;&#160;»
        </p>

      </div>

    <div class="footer" role="contentinfo">
        &#169; Copyright 2017, Marlon Weinert.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.5.1.
    </div>
  </body>
</html>